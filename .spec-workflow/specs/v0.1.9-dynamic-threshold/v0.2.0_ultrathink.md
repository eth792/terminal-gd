# v0.2.0 Ultrathink Analysis

**日期**: 2025-11-19
**目标**: 突破 F2 瓶颈，提升项目名称匹配准确率

---

## 核心数据洞察

### 1. F2 是主要瓶颈

| 指标 | F1（供应商） | F2（项目） | 差值 |
|------|-------------|-----------|------|
| 全局平均 | 0.748 | 0.607 | **-0.142** |

**结论**: F2 比 F1 低 0.142，项目名称匹配是主要瓶颈。

---

### 2. Exact 案例的 F2 分布

| 统计 | 值 |
|------|-----|
| 数量 | 71 |
| F2 平均 | 0.896 |
| F2 中位数 | 0.910 |
| F2 范围 | [0.754, 1.000] |
| **F2 < 0.8 的案例** | **9/71 (12.7%)** |

**洞察**：
- ✅ Exact 案例的 F2 普遍很高（平均 0.896）
- ⚠️ 但仍有 9 个案例 F2 < 0.8（它们靠 Rule 5 高置信度旁路通过）

---

### 3. FIELD_SIM_LOW_PROJECT 失败案例的 F2 分布

| 统计 | 值 |
|------|-----|
| 数量 | 60 |
| F2 平均 | **0.324** |
| F2 中位数 | 0.331 |
| F2 范围 | [0.000, 0.599] |
| **F2 > 0.5 的案例** | **7/60 (11.7%)** |

**洞察**：
- ❌ 失败案例的 F2 极低（平均 0.324）
- ❌ 中位数 0.331 远低于 0.6 阈值
- ✅ 但有 7 个案例 F2 > 0.5（接近阈值，提升后可通过）

---

### 4. 潜在收益评估

**假设**：如果 F2 提升 0.1

| 来源 | 数量 | 说明 |
|------|------|------|
| Rule 3/4 潜在通过 | 7 | FIELD_SIM_LOW_PROJECT 案例，f2+0.1 >= 0.6 |
| Rule 7 潜在通过 | 21 | DELTA_TOO_SMALL 案例，f2 提升后通过 |
| **总计** | **28** | **+39.4%** |

**预期 KPI**：
- Exact: 71 → **99** (+28)
- Auto-pass rate: 32.0% → **44.6%** (+12.6pp)

---

### 5. Top 10 最有希望的失败案例

| Filename | F1 | F2 | Score |
|----------|----|----|-------|
| baoshengkejichuangxingufenyouxiangongsi4100962417.txt | 0.521 | **0.599** | 0.560 |
| wuhanwuhudianlan4100967039-a.txt | 0.000 | **0.595** | 0.298 |
| tonglidaxianlan4100961838.txt | 0.000 | **0.559** | 0.279 |
| dingshengjituanyouxiangongsi4100908097.txt | 0.036 | 0.531 | 0.284 |
| dingshengjituanyouxiangongsi4100965875.txt | 0.036 | 0.531 | 0.284 |
| shenzhenshichengtiantaidianlanshiyefazhanyouxiangongsi4100971450-2.txt | 0.000 | 0.528 | 0.264 |
| pengyoudianlikejiyouxiangongsi4100962424.txt | 0.041 | 0.509 | 0.275 |
| jiangsuzhongtiankejigufenyouxiangongsi4100961781.txt | **1.000** | 0.496 | 0.748 |
| baoshengkejichuangxingufenyouxiangongsi4100931841.txt | **1.000** | 0.476 | 0.738 |
| jiangsuzhongtiankejigufenyouxiangongsi4100961794.txt | **1.000** | 0.475 | 0.738 |

**关键模式**：
1. **F2 在 0.47-0.60 区间**：只需提升 0.1-0.15 即可通过阈值
2. **F1 两极分化**：
   - 3 个案例 F1 = 1.0（供应商完美匹配）
   - 7 个案例 F1 ≈ 0（供应商匹配失败）
3. **高 F1 + 中等 F2**：最有希望的案例（如第 8-10 个）

---

## 根本问题分析

### 为什么 F2 这么低？

#### 假设 1：OCR 提取不完整
- 项目名称被截断或提取错误
- 需要检查 Top 10 案例的实际 OCR 文本

#### 假设 2：当前算法问题
当前 F2 计算使用 **RapidFuzz ratio**（纯字符级别相似度）：

```python
f2_score = rapidfuzz.fuzz.ratio(q_project, cand_project)
```

**问题**：
- ❌ 不考虑语义和词语边界
- ❌ 项目名称包含多个实体（公司名、项目名、期数）
- ❌ 顺序变化、括号、标点符号影响巨大

**示例**（推测）：
```
OCR:  "武汉花桥嘉城实业有限公司花桥村城中村改造"
DB:   "武汉花桥嘉城实业有限公司"花桥村城中村改造"一期"
Ratio: 0.55（因为缺少"一期"）
```

#### 假设 3：DB 数据质量问题
- DB 中项目名称格式不统一
- 包含额外的引号、括号、备注信息

---

## v0.2.0 技术方案（待验证）

### 方案 A：Substring Weighting（子串加权）

**核心思想**：将项目名称拆分为多个 token，按重要性加权匹配。

```python
def calculate_f2_weighted(q_project, cand_project):
    # 1. 分词（按标点和空格）
    q_tokens = tokenize(q_project)
    cand_tokens = tokenize(cand_project)

    # 2. 为每个 token 打分
    #    - 公司名: 权重 0.4
    #    - 项目主体名: 权重 0.4
    #    - 期数/地块: 权重 0.2

    # 3. Token-level matching
    matched_weight = 0
    total_weight = 1.0

    for q_token in q_tokens:
        best_match = max(ratio(q_token, ct) for ct in cand_tokens)
        if best_match > 0.8:
            matched_weight += get_weight(q_token)

    return matched_weight / total_weight
```

**预期效果**：
- ✅ 容忍顺序变化
- ✅ 部分匹配也能得高分
- ⚠️ 需要设计 token 权重规则（复杂）

---

### 方案 B：N-gram Overlap + Token Set

**核心思想**：结合字符级和词级相似度。

```python
def calculate_f2_hybrid(q_project, cand_project):
    # 1. 字符级 n-gram（3-gram）
    char_sim = trigram_similarity(q_project, cand_project)

    # 2. 词级 token set
    token_sim = token_set_ratio(q_project, cand_project)

    # 3. 加权组合
    return 0.6 * char_sim + 0.4 * token_sim
```

**RapidFuzz 已有实现**：
- `fuzz.token_set_ratio`: 忽略顺序和重复
- `fuzz.partial_ratio`: 子串匹配

**预期效果**：
- ✅ 简单，利用现有库
- ✅ 容忍顺序和部分匹配
- ⚠️ 权重需要调优

---

### 方案 C：Semantic Matching（语义匹配）

**核心思想**：使用 embedding 计算语义相似度。

```python
def calculate_f2_semantic(q_project, cand_project):
    # 1. 使用 sentence-transformers
    emb_q = model.encode(q_project)
    emb_cand = model.encode(cand_project)

    # 2. 余弦相似度
    return cosine_similarity(emb_q, emb_cand)
```

**预期效果**：
- ✅ 理解语义（"一期" vs "二期" 相似度高）
- ❌ 复杂度高（需要模型）
- ❌ 性能开销大

---

## 下一步行动

### Step 1: 案例研究（必做）
**目标**：验证假设，确定根本问题

1. 读取 Top 10 失败案例的实际 OCR 文本
2. 对比 DB 中的项目名称
3. 手工分析为什么 F2 低

**输出**：
- 真实案例清单
- 根本问题确认
- 算法方向选择

### Step 2: 方案选择
根据 Step 1 结果，选择方案 A、B 或 C。

**判断标准**：
- 简单性（Linus: 简洁执念）
- 可解释性（能理解为什么提升）
- 性能（O(N) 复杂度）

### Step 3: Spec 创建
使用 spec-workflow 创建 v0.2.0 spec：
- Requirements: 提升 F2，目标 +28 exact
- Design: 选定的算法方案
- Tasks: 实施步骤
- Implementation: 代码变更

---

## 风险评估

### 高风险
1. **算法复杂度爆炸**：Token weighting 规则难以维护
2. **性能回退**：复杂算法可能显著增加耗时
3. **过度优化**：针对 Top 10 案例优化，泛化性差

### 缓解措施
1. **数据驱动**：基于 100+ 案例验证，不只看 Top 10
2. **性能基准**：要求新算法 <= 1.5x 当前耗时
3. **回滚计划**：保留当前算法作为 fallback

---

**结论**：v0.2.0 有明确的数据支撑和巨大潜力（+39.4% exact），但需要先完成 Step 1 案例研究，确保方向正确。
